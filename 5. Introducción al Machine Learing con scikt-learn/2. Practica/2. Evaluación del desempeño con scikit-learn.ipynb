{"cells":[{"cell_type":"markdown","metadata":{"id":"fEewD2N0RkMc"},"source":["# **Evaluación del desempeño con *Scikit-Learn***\n","---\n","\n","En esta tarea deberá entrenar un modelo de clasificación para el [conjunto de datos de vinos _Wine_](https://archive.ics.uci.edu/ml/datasets/wine) del repositorio de la *UCI* usando *Scikit-learn*.\n","\n","El conjunto de datos cuenta con información de análisis químico en lotes de vinos cosechados en la misma región de Italia en $3$ cultivos distintos.\n","\n","\n","| Variable | Medida\t| Valores | \n","| --- | --- | --- |\n","| alcohol | \tPorcentaje de alcohol. | \tnumérico |\n","| malic_acid \t|  Ácido málico. | \tnumérico\n","| ash \t| Cenizas (restos inorgánicos). \t| numérico|\n","| alcalinity_of_ash |\tAlcalinidad de la ceniza. \t| numérico|\n","| magnesium |\tMagnesio. \t| numérico|\n","| total_phenols |\tFenoles totales. \t| numérico|\n","| flavanoids |\t Flavonoides. \t| numérico|\n","| nonflavanoid_phenols |\tFenoles no flavonoides. \t| numérico|\n","| proanthocyanins |\tProantocianidinas. \t| numérico|\n","| color_intensity |\tIntensidad del color. \t| numérico|\n","| hue |\tTonalidad del color. \t| numérico|\n","| od280/od315_of_diluted_wines |\t Concentración de proteínas (OD280/OD315). \t| numérico|\n","| proline |\tProlino. \t| numérico|\n","\n"]},{"cell_type":"markdown","metadata":{"id":"S-ocd--frFi7"},"source":["Ejecute la siguiente celda para importar y configurar las librerías usadas:"]},{"cell_type":"code","execution_count":1,"metadata":{"id":"PIB7qeOuVkfh"},"outputs":[],"source":["# Actualizamos a la última versión disponible de scikit-learn.\n","# !pip install -U scikit-learn\n","\n","import sklearn\n","\n","# Librerías de utilidad para manipulación y visualización de datos.\n","from numbers import Number\n","import numpy as np\n","import pandas as pd"]},{"cell_type":"code","execution_count":2,"metadata":{"id":"nm_ulccYMeUn"},"outputs":[],"source":["#TEST_CELL\n","# Configuramos el formato por defecto de la \n","# librería de visualización Matplotlib.\n","import seaborn as sns\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","mpl.rcParams['figure.dpi'] = 110\n","mpl.rcParams['figure.figsize'] = (8, 6)\n","sns.set_theme()"]},{"cell_type":"markdown","metadata":{"id":"29w9RP8pnPJv"},"source":["## **1. Cargar *Wine* en formato X, y**\n","-------\n","Antes de comenzar el proceso de modelado deberá identificar el conjunto de datos discutido y cargarlo en el formato adecuado.\n","\n","Complete la función **`load_X_y`** de tal manera que cargue el conjunto de datos *Wine* en el formato **`X, y`**.\n","El arreglo **`X`** debe corresponder a las características del conjunto de datos y **`y`** a las etiquetas.\n","\n","**Salida**:\n","* **`X`**: arreglo de *NumPy* de $2$ dimensiones con las variables de entrada del conjunto de datos *Wine* (medidas de concentraciones de sustancias químicas en cosechas de vino).\n","* **`y`**: arreglo de *NumPy* de $1$ dimensión con la variable de salida del conjunto de datos *Wine* (cultivo al que pertenece la medida)."]},{"cell_type":"markdown","metadata":{},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista</b></font>\n","</summary>\n","\n","* Consulte la [lista de conjuntos de datos](https://scikit-learn.org/stable/datasets/toy_dataset.html) disponibles como *loaders* en el módulo **`sklearn.datasets`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NjOczYfpnaoR"},"outputs":[],"source":["# FUNCIÓN CALIFICADA load_X_y:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import datasets\n","\n","def load_X_y():\n","  \"\"\"\n","  Retorna:\n","    X: arreglo de NumPy de tamaño (150, 4) que representa las \n","            variables de entrada del conjunto Wine. \n","    y: arreglo de NumPy de tamaño (150,) que representa la variable \n","            de salida (etiqueta).\n","  \"\"\"\n","  ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 1 línea de código)\n","  \n","  X, y = None, None\n","  \n","  ### FIN DEL CÓDIGO ###\n","\n","  return X, y"]},{"cell_type":"markdown","metadata":{"id":"YuxmkRGBnvbi"},"source":["Use la siguiente celda para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Cva_57Mgn0sC"},"outputs":[],"source":["#TEST_CELL\n","X, y = load_X_y()\n","\n","if isinstance(X, np.ndarray) and isinstance(y, np.ndarray):\n","  print(\"El shape de X es:\", X.shape)\n","  print(\"El shape de y es:\", y.shape)\n","else: \n","  print(\"El tipo de los objetos es incorrecto.\")"]},{"cell_type":"markdown","metadata":{"id":"SWjnAGXrsi22"},"source":["**Salida esperada:**\n"," \n"," ```\n","El shape de X es: (178, 13)\n","El shape de y es: (178,)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ATPNx6_lNBlO"},"outputs":[],"source":["#TEST_CELL\n","if isinstance(y, np.ndarray):\n","  print(np.bincount(y)) # Conteo de repeticiones por clase.\n","else: \n","  print(\"El tipo del objetos 'y' es incorrecto.\")"]},{"cell_type":"markdown","metadata":{"id":"LuvB3imHNUPH"},"source":["**Salida esperada:**\n"," \n"," ```\n","[59 71 48]\n","```"]},{"cell_type":"markdown","metadata":{"id":"7Qc3Co25b2fQ"},"source":["Ejecute la siguiente celda (después de completar el punto anterior) para visualizar la distribución de etiquetas del conjunto de datos Iris."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Fxs3wH-dbowE"},"outputs":[],"source":["#TEST_CELL\n","X, y = load_X_y()\n","sns.countplot(x = y);"]},{"cell_type":"markdown","metadata":{"id":"J-1x6GbPr4wM"},"source":["Debería ver un conjunto de datos ligeramente desbalanceado con $178$ ejemplos."]},{"cell_type":"markdown","metadata":{"id":"4NjgUB-JFFCR"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","* Consulte la [lista de conjuntos de datos](https://scikit-learn.org/stable/datasets/toy_dataset.html) disponibles como *loaders* en el módulo **`sklearn.datasets`**.\n"]},{"cell_type":"markdown","metadata":{"id":"9-Vnu3j7unFd"},"source":["## **2. Problema de clasificación binaria**\n","---\n","En esta actividad abordaremos primero el *dataset* como un problema de clasificación binaria, y más adelante, uno de clasificación multiclase.\n","\n","Complete la función **`bin_X_y`**, que seleccione solo los ejemplos de la clase $0$ y $1$ tanto para **`X`** como para **`y`** y retorne los dos conjuntos reducidos. **El orden de los datos conservados se debe mantener**.\n","\n","**Entrada**:\n","\n","* **`X`**: arreglo de *NumPy* de tamaño $(n, m)$.\n","* **`y`**: arreglo de *NumPy* de tamaño $(n, )$.\n","\n","\n","**Salida**:\n","* **`X_bin`**:  arreglo de *NumPy* de tamaño $(n^\\prime, m)$ con los registros de **`X`** que correspondan a las clases $0$ y $1$ del vector de etiquetas **`y`**.\n","* **`y_bin`**:  arreglo de *NumPy* de tamaño $(n^\\prime,)$ con los registros del vector de etiquetas **`y`** que correspondan a las clases $0$ y $1$.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"DyV6b2ZVu_dl"},"outputs":[],"source":["# FUNCIÓN CALIFICADA bin_X_y:\n","\n","def bin_X_y(X, y):\n","    \"\"\"\n","    X: una matriz de datos, arreglo de NumPy de tamaño (n, m)\n","    y: un vector de etiquetas, arreglo de NumPy de tamaño (n,)    \n","\n","  Retorna:     \n","    X_bin:  arreglo de NumPy de tamaño (n', m) con los registros de X que \n","            correspondan a las clases  0  y  1  del vector de etiquetas y.\n","    y_bin:  arreglo de NumPy de tamaño (n',) con los registros del vector\n","            de etiquetas y que correspondan a las clases 0 y  1.\n","    \"\"\"\n","\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 2 líneas de código)\n","  \n","    X_bin = None\n","    y_bin = None\n","  \n","    ### FIN DEL CÓDIGO ###\n","    return X_bin, y_bin"]},{"cell_type":"markdown","metadata":{"id":"GSg9xPO0veXg"},"source":["Use la siguiente celda para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"aUDHftIDUoj8"},"outputs":[],"source":["#TEST_CELL\n","X2 = np.arange(40).reshape(10, 4)\n","y2 = np.array([1, 0, 2, 1, 0, 2, 0, 2, 2, 0])\n","\n","X_bin, y_bin = bin_X_y(X2, y2)\n","\n","if isinstance(X_bin, np.ndarray) and isinstance(y_bin, np.ndarray):\n","  print(\"El shape de X_bin es:\", X_bin.shape)\n","  print(\"El shape de y_bin es:\", y_bin.shape)\n","else: \n","  print(\"El tipo de los objetos es incorrecto.\")"]},{"cell_type":"markdown","metadata":{"id":"RL-v3NygVrrb"},"source":["**Salida esperada:**\n"," \n"," ```\n","El shape de X_bin es: (6, 4)\n","El shape de y_bin es: (6,)\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"v2rWcWm8V5cT"},"outputs":[],"source":["#TEST_CELL\n","X2 = np.arange(40).reshape(10, 4)\n","y2 = np.array([1, 0, 2, 1, 0, 2, 0, 2, 2, 0])\n","\n","X_bin, y_bin = bin_X_y(X2, y2)\n","\n","if isinstance(X_bin, np.ndarray):\n","  print(X_bin)\n","else: \n","  print(\"El tipo del objeto 'X_bin' es incorrecto.\")"]},{"cell_type":"markdown","metadata":{"id":"whUZVLiPV5cU"},"source":["**Salida esperada:**\n"," \n"," ```\n","[[ 0  1  2  3]\n"," [ 4  5  6  7]\n"," [12 13 14 15]\n"," [16 17 18 19]\n"," [24 25 26 27]\n"," [36 37 38 39]]\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pWIiRFeVZ9-n"},"outputs":[],"source":["#TEST_CELL\n","X2 = np.arange(40).reshape(10, 4)\n","y2 = np.array([1, 0, 2, 1, 0, 2, 0, 2, 2, 0])\n","\n","X_bin, y_bin = bin_X_y(X2, y2)\n","\n","if isinstance(y_bin, np.ndarray):\n","  print(y_bin)\n","else: \n","  print(\"El tipo del objeto 'y_bin' es incorrecto.\")"]},{"cell_type":"markdown","metadata":{"id":"gmF52C5aZ9-s"},"source":["**Salida esperada:**\n"," \n"," ```\n","[1 0 1 0 0 0]\n","```"]},{"cell_type":"markdown","metadata":{"id":"EKAXtJ29QfK1"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* En *NumPy* se puede realizar selección condicional con la siguiente sintaxis: **`X[cond]`**, donde **`cond`** corresponde a un arreglo de valores booleanos con el mismo tamaño en la dimensión $0$ (filas).\n"]},{"cell_type":"markdown","metadata":{"id":"nMn59ZFKFGfY"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n","</summary>\n","\n","\n","* En *NumPy* se puede realizar selección condicional de valores específicos con la siguiente sintaxis: **`X[X op a]`**, donde **`op`** corresponde a un operador lógico (**`==`**, **`!=`**,  **`>`**,  **`>=`**,  **`<`**,  **`<=`**, etc).\n"]},{"cell_type":"markdown","metadata":{"id":"bf6nCebsRVif"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 3</b></font>\n","</summary>\n","\n","\n","* Debería usar los valores condicionales de las clases del vector de etiquetas **`y`** para seleccionar los valores tanto en el arreglo **`y`** como en  **`X`**.\n"]},{"cell_type":"markdown","metadata":{"id":"pXXcFvaPXPE4"},"source":["##  **3. Generar particiones de entrenamiento y prueba con estratificación**\n","---\n","Cuando se trata con datos con clases desbalanceadas se corre el riesgo de que los resultados obtenidos se vean alterados por el sesgo de muestreo. Al realizar una partición aleatoria se considera buena práctica definir un criterio de estratificación, como el uso de clases o características categóricas para preservar la frecuencia relativa de aparición de cada clase en los subconjuntos generados.\n","\n","Complete la función **`get_stratified_split`** de tal manera que haga una partición de los datos en los conjuntos de entrenamiento y prueba estratificados por las clases del vector de etiquetas usando *Scikit-learn*. \n","\n","> **Nota:** La función creada deberá aceptar un argumento para definir el tamaño relativo de la partición de prueba (**`p`**) y otro para definir la semilla aleatoria (**`random_state`**) para garantizar la reproducibilidad.\n","\n","**Entrada**:\n","\n","* **`X`**: arreglo de *NumPy* de tamaño $(n, m)$.\n","* **`y`**: arreglo de *NumPy* de tamaño $(n, )$.\n","* **`p`**: número real entre $0$ y $1$ con la proporción correspondiente a la partición de prueba.\n","* **`random_state`**: número real con la semilla aleatoria para la generación de la partición.\n","\n","**Salida**:\n","* **`X_train`**: arreglo de *NumPy* con *shape* aproximado $(n\\cdot (1-p), m)$ para la partición de entrenamiento de **`X`**.\n","* **`X_test`**:  arreglo de *NumPy* con *shape* aproximado $(n\\cdot p, m)$ para la partición de prueba de **`X`**.\n","* **`y_train`**: arreglo de *NumPy* con *shape* aproximado $(n \\cdot (1-p),)$ para la partición de entrenamiento de **`y`**.\n","* **`y_test`**:  arreglo de *NumPy* con *shape* aproximado $(n\\cdot p,)$ para la partición de prueba de **`y`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Kb_Fg2knB9wZ"},"outputs":[],"source":["# FUNCIÓN CALIFICADA get_stratified_split:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import model_selection\n","\n","def get_stratified_split(X, y, \n","# ¡No modifique los valores por defecto de los argumentos!\n","              p=0.3, random_state=42): \n","  \"\"\"\n","    X: matriz de datos, arreglo de NumPy con shape (n, m).\n","    y: vector de etiquetas, arreglo de NumPy con shape (n,).\n","    p: proporción de los datos para la partición de prueba,\n","       número real entre 0 y 1.\n","    random_state: semilla aleatoria.\n","\n","  Retorna: \n","    X_train: arreglo de NumPy con shape aproximado (n(1 - p), m) \n","              para la partición de entrenamiento de X.\n","    X_test:  arreglo de NumPy con shape aproximado (n(p), m) \n","              para la partición de prueba de X.\n","    y_train: arreglo de NumPy con shape aproximado (n(1 - p),) \n","              para la partición de entrenamiento de y.\n","    y_test:  arreglo de NumPy con shape aproximado (n(p),) \n","              para la partición de prueba de y.\n","  \"\"\"\n","  ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 2 líneas de código)\n","  \n","  X_train, X_test, y_train, y_test = None, None, None, None\n","\n","  ### FIN DEL CÓDIGO ###\n","\n","  return X_train, X_test, y_train, y_test"]},{"cell_type":"markdown","metadata":{"id":"XvZOXF8OFjHe"},"source":["Use la siguiente celda para probar su partición:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TNouhOiFFjHf"},"outputs":[],"source":["#TEST_CELL\n","X3 = np.arange(500).reshape(100, 5)\n","y3 = np.repeat([0,1], [25, 75])\n","\n","X_train, X_test, y_train, y_test = get_stratified_split(X3, y3)\n","\n","if np.all([isinstance(p, np.ndarray) for p in (X_train, X_test, y_train, y_test)]):\n","  print('I. Partición de entrenamiento:\\n')\n","\n","  print(f\"Tamaño de X: {X_train.shape}\")\n","  print(f\"Primeros 5 valores de X:\")\n","  print(X_train[:5, :])\n","\n","  print(f\"Primeros 5 valores de y: {y_train[:5]}\")\n","  print(f\"Valores únicos de y:\", np.bincount(y_train))\n","\n","  print('\\nII. Partición de prueba:\\n')\n","  print(f\"Tamaño de X: {X_test.shape}\")\n","\n","  print(f\"Primeros 5 valores de X:\")\n","  print(X_test[:5, :])\n","  print(f\"Primeros 5 valores de y: {y_test[:5]}\")\n","  print(f\"Valores únicos de y:\", np.bincount(y_test))\n","else:\n","  print(\"Alguno de los objetos asignado no es un arreglo de NumPy válido.\")"]},{"cell_type":"markdown","metadata":{"id":"_xmwEFfBJ43x"},"source":["**Salida esperada**:\n","\n","```\n","I. Partición de entrenamiento:\n","\n","Tamaño de X: (70, 5)\n","Primeros 5 valores de X:\n","[[390 391 392 393 394]\n"," [495 496 497 498 499]\n"," [370 371 372 373 374]\n"," [260 261 262 263 264]\n"," [295 296 297 298 299]]\n","Primeros 5 valores de y: [1 1 1 1 1]\n","Valores únicos de y: [17 53]\n","\n","II. Partición de prueba:\n","\n","Tamaño de X: (30, 5)\n","Primeros 5 valores de X:\n","[[405 406 407 408 409]\n"," [ 90  91  92  93  94]\n"," [460 461 462 463 464]\n"," [100 101 102 103 104]\n"," [440 441 442 443 444]]\n","Primeros 5 valores de y: [1 0 1 0 1]\n","Valores únicos de y: [ 8 22]\n","```"]},{"cell_type":"markdown","metadata":{"id":"ohxc4uRw9Gqb"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Utilice la función [**`train_test_split`**](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html) del módulo **`sklearn.model_selection`** tal como se vio en el taller guiado de la **Unidad 1**.\n"]},{"cell_type":"markdown","metadata":{"id":"-ZfSsVlb9NWs"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n","</summary>\n","\n","\n","* El argumento **`p`** permite definir la cantidad de datos usados para el subconjunto de pruebas. Si tiene problemas con el tamaño de la partición puede hacer falta usar este argumento en el llamado de la función de generación de particiones.\n"]},{"cell_type":"markdown","metadata":{"id":"gZzpshRRwX6X"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 3</b></font>\n","</summary>\n","\n","\n","* Considere el argumento **`random_state`** de su función y úselo como argumento de la función de generación de particiones de *Scikit-learn*. Como la partición se hace con un proceso aleatorio, omitir este argumento produciría un valor distinto cada vez que se ejecute.\n"]},{"cell_type":"markdown","metadata":{"id":"oZi1f1IhR-Bw"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 4</b></font>\n","</summary>\n","\n","\n","* No olvide indicar a *Scikit-Learn* el arreglo sobre el cual debe realizar la estratificación. Esto se puede hacer con el argumento **`stratify`** de **`train_test_split`**.\n"]},{"cell_type":"markdown","metadata":{"id":"DVeqXFAvxUsf"},"source":["## **4. Entrenamiento de un clasificador de $k$ vecinos más cercanos**\n","---\n","Para este caso utilizaremos un clasificador basado en el algoritmo de $k$ vecinos más cercanos. Este debe permitir el uso de datos binarios y multiclase en el proceso de entrenamiento.\n","\n","Escriba la función **`clasificador_knn`** que reciba como datos de entrada las características **`X`** y sus respectivas etiquetas **`y`**. Además, construya un clasificador **`KNeighborsClassifier`** que considere los **`k`** vecinos más cercanos.\n","\n","**Entrada**:\n","* **`X`**: arreglo de *NumPy* de tamaño $(n, m)$.\n","* **`y`**: arreglo de *NumPy* de tamaño $(n, )$.\n","* **`k`**: número entero mayor o igual a $1$ con el número de vecinos a considerar en el algoritmo *KNN*.\n","\n","**Salida**:\n","* **`knn`**: modelo de clasificación basado en el algoritmo *KNN* entrenado a partir de los datos de entrada (características **`X`** y etiquetas **`y`**).\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"c3fsXBv3yHSw"},"outputs":[],"source":["# FUNCIÓN CALIFICADA clasificador_knn:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import neighbors\n","\n","def clasificador_knn(X, y, k):\n","    \"\"\"\n","     X: arreglo de NumPy de shape (n, m) con las características.\n","     y: arreglo de NumPy de shape (n,) con las etiquetas de clase.\n","     k: número entero, el número de vecinos más cercanos a considerar.\n","    Retorna:\n","     knn: Clasificador de los k vecinos más cercanos entrenado con X y y.\n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 2 líneas de código)\n","  \n","    knn = None\n","\n","    ### FIN DEL CÓDIGO ###\n","    return knn"]},{"cell_type":"markdown","metadata":{"id":"uqmotEvLyZSx"},"source":["Use las siguientes celdas para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"_PMHdYs0ycDA"},"outputs":[],"source":["#TEST_CELL\n","X4, y4 = datasets.make_blobs(centers = 2, random_state = 4)\n","\n","bin_clf = clasificador_knn(X4[:75], y4[:75], 2)\n","if isinstance(bin_clf, sklearn.neighbors._classification.KNeighborsClassifier):\n","  print(bin_clf.score(X4[75:], y4[75:]))"]},{"cell_type":"markdown","metadata":{"id":"DA0dELHoZkcq"},"source":["**Salida esperada**:\n","```\n","0.92\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lU5I1CnSZpeO"},"outputs":[],"source":["#TEST_CELL\n","X4, y4 = datasets.make_blobs(centers = 2, random_state = 4)\n","\n","bin_clf = clasificador_knn(X4[:75], y4[:75], 2)\n","if isinstance(bin_clf, sklearn.neighbors._classification.KNeighborsClassifier):  \n","  print(bin_clf.predict(X4[75:]))"]},{"cell_type":"markdown","metadata":{"id":"TuoJAw9PZpeP"},"source":["**Salida esperada**:\n","```\n","[0 1 0 1 1 1 1 1 1 0 0 1 0 1 1 1 1 1 0 1 0 0 1 1 0]\n","```"]},{"cell_type":"markdown","metadata":{"id":"CUo46WMhFHX4"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Utilice el constructor **`KNeighborsClassifier`** del módulo **`sklearn.neighbor`** tal como se vio en el taller guiado de la **Unidad 2**.\n"]},{"cell_type":"markdown","metadata":{"id":"dGER6Lv_9ujt"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n","</summary>\n","\n","* No olvide entrenar su modelo con la función **`fit`**. De lo contrario, es posible que la predicción de la celda de pruebas falle.\n"]},{"cell_type":"markdown","metadata":{"id":"sfeS7LoKz6TV"},"source":["## **5. Falsos positivos y falsos negativos**\n","----\n","Al obtener las predicciones de un modelo de clasificación binaria se pueden presentar dos tipos de error. El primero consiste en aceptar como positiva una observación que no debería (**falso positivo**) y el segundo en rechazar una observación que sí debía ser aceptada (**falso negativo**).\n","\n","Desarrolle la función **`fp_fn`** para que calcule el número de falsos positivos y el número de falsos negativos que un clasificador binario (no necesariamente basado en *KNN*) produce sobre un conjunto de datos dado. \n","\n","> En este caso un falso positivo es un ejemplo que es realmente de la clase $0$ pero es clasificado en la clase $1$ y un falso negativo es un ejemplo que es realmente de la clase $1$ pero es clasificado en la clase $0$.\n","\n","**Entrada**:\n","  * **`clf`**: clasificador binario de *Scikit-Learn* entrenado.\n","  * **`X`**: arreglo de *NumPy* de tamaño $(n, m)$ usado para la evaluación.\n","  * **`y`**: arreglo de *NumPy* de tamaño $(n, )$ usado para la evaluación.\n","\n","**Salida**:\n","\n","  * **`fp`**: falsos positivos de las predicciones de **`clf`** sobre **`X`** y las etiquetas reales **`y`**.\n","  * **`fn`**: falsos negativos de las predicciones de **`clf`** sobre **`X`** y las etiquetas reales **`y`**."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BBvzK02N1zRE"},"outputs":[],"source":["# FUNCIÓN CALIFICADA fp_fn:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import metrics\n","\n","def fp_fn(clf, X, y):\n","    \"\"\"\n","     clf: clasificador binario entrenado.\n","     X: arreglo de NumPy de tamaño (n, m) con las características.\n","     y: arreglo de NumPy de tamaño (n,) con las etiquetas de clase.\n","    Retorna:\n","     fp: falsos positivos de las predicciones de clf sobre X y las etiquetas reales y.\n","     fn: falsos negativos de las predicciones de clf sobre X y las etiquetas reales y.\n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 3-4 líneas de código)\n","  \n","    fp, fn = None, None\n","\n","    ### FIN DEL CÓDIGO ###\n","    return fp, fn"]},{"cell_type":"markdown","metadata":{"id":"7tqytfz92o2v"},"source":["Use la siguiente celda para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1JcAvnXt3vNw"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.linear_model import LogisticRegression\n","\n","X5, y5 = datasets.make_circles(random_state = 8)\n","clf = LogisticRegression().fit(X5[:50], y5[:50])\n","\n","fp, fn = fp_fn(clf, X5[:50], y5[:50])\n","print(f\"Falsos positivos en entrenamiento: {fp}\")\n","print(f\"Falsos negativos en entrenamiento: {fn}\")"]},{"cell_type":"markdown","metadata":{"id":"lSnwfn8Rdxmr"},"source":["**Salida esperada**:\n","```\n","Falsos positivos en entrenamiento: 6\n","Falsos negativos en entrenamiento: 16\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"rUXCxfnEb6q5"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.linear_model import LogisticRegression\n","\n","X5, y5 = datasets.make_circles(random_state = 8)\n","clf = LogisticRegression().fit(X5[:50], y5[:50])\n","\n","fp, fn = fp_fn(clf, X5[50:], y5[50:])\n","print(f\"Falsos positivos en pruebas: {fp}\")\n","print(f\"Falsos negativos en pruebas: {fn}\")"]},{"cell_type":"markdown","metadata":{"id":"jfx41xtkdyBg"},"source":["**Salida esperada**:\n","```\n","Falsos positivos en pruebas: 11\n","Falsos negativos en pruebas: 19\n","```"]},{"cell_type":"markdown","metadata":{"id":"x8FuXnTkFIHb"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Puede obtener el valor de falsos positivos y falsos negativos a partir de la matriz de confusión obtenida del vector **`y`** y el vector de etiquetas predichas a partir de **`X`**. Deberá seleccionar las celdas correspondientes a cada valor y asignarlo a la variable correspondiente.\n"]},{"cell_type":"markdown","metadata":{"id":"xlUPahTE5QOa"},"source":["## **6. Métricas de desempeño binarias**\n","----\n","Al desarrollar un modelo de clasificación binaria se puede recurrir a la evaluación por métricas distintas a la exactitud o *accuracy* que reflejen más información acerca de el desempeño con respecto a las clases predichas.\n","\n","Desarrolle la función **`métricas_binarias`** que calcule la precisión, el *recall* y la métrica $F_1$ de las predicciones hechas por un clasificador binario sobre un conjunto de datos dado. \n","> Recuerde que en este caso la etiqueta positiva es la clase $1$.\n","\n","**Entrada**:\n","  * **`clf`**: clasificador binario de *Scikit-Learn* entrenado.\n","  * **`X`**: arreglo de *NumPy* de tamaño $(n, m)$ usado para la evaluación.\n","  * **`y`**: arreglo de *NumPy* de tamaño $(n, )$ usado para la evaluación.\n","\n","**Salida**:\n","\n","  * **`prec`**: número real, métrica de precisión binaria.\n","  * **`rec`**: número real, métrica de _recall_ binaria.\n","  * **`f1`**:  número real, métrica _$F_1$-score_ binaria."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TURh1ZSx6irb"},"outputs":[],"source":["# FUNCIÓN CALIFICADA métricas_binarias:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import metrics\n","\n","def métricas_binarias(clf, X, y):\n","    \"\"\"\n","      clf: clasificador entrenado,\n","      X: arreglo de NumPy de tamaño (n, m) con las características.\n","      y: arreglo de NumPy de tamaño (n,) con las etiquetas de clase.\n","    Retorna:\n","      prec: número real, métrica de precisión binaria.\n","      rec: número real, métrica de recall binaria.\n","      f1:  número real, métrica f1-score binaria.\n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 3-4 líneas de código)\n","  \n","    prec, rec, f1 = None, None, None\n","\n","    ### FIN DEL CÓDIGO ###\n","\n","    return prec, rec, f1"]},{"cell_type":"markdown","metadata":{"id":"kW3JVLh87qDq"},"source":["Use la siguiente celda para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H-TUYWXn7rEX"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.linear_model import LogisticRegression\n","\n","X6, y6 = datasets.make_classification(random_state = 8)\n","bin_clf6 = LogisticRegression().fit(X6[:50], y6[:50])\n","prec, rec, f1 = métricas_binarias(bin_clf6, X6[:50], y6[:50])\n","\n","if np.all([isinstance(x, Number) for x in [prec, rec, f1]]):  \n","  print(\"Precisión en entrenamiento: \\t{:.4f}\".format(prec))\n","  print(\"Recall en entrenamiento: \\t{:.4f}\".format(rec))\n","  print(\"F1 en entrenamiento: \\t\\t{:.4f}\".format(f1))\n","else: print(\"Alguno de los valores retornados no es un número válido.\")"]},{"cell_type":"markdown","metadata":{"id":"JgrD7FwJnvI3"},"source":["**Salida esperada**:\n","```\n","Precisión en entrenamiento: \t0.9615\n","Recall en entrenamiento: \t   0.9615\n","F1 en entrenamiento: \t\t   0.9615\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TwJUdtGTebVd"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.linear_model import LogisticRegression\n","\n","X6, y6 = datasets.make_classification(random_state = 8)\n","bin_clf6 = LogisticRegression().fit(X6[:50], y6[:50])\n","prec, rec, f1 = métricas_binarias(bin_clf6, X6[50:], y6[50:])\n","\n","if np.all([isinstance(x, Number) for x in [prec, rec, f1]]):  \n","  print(\"Precisión en prueba: \\t{:.4f}\".format(prec))\n","  print(\"Recall en prueba: \\t{:.4f}\".format(rec))\n","  print(\"F1 en prueba: \\t\\t{:.4f}\".format(f1))\n","else: print(\"Alguno de los valores retornados no es un número válido.\")"]},{"cell_type":"markdown","metadata":{"id":"ePBl7tVunviZ"},"source":["**Salida esperada**:\n","```\n","Precisión en prueba:    0.6333\n","Recall en prueba:       0.7600\n","F1 en prueba:           0.6909\n","```"]},{"cell_type":"markdown","metadata":{"id":"duNAOYx5zlX9"},"source":["Para probar la función vamos a entrenar un clasificador para las $2$ primeras clases originales del conjunto de datos *Wine*. \n","> **Nota**: El resultado de esta celda depende de la correctitud de los primeros puntos de esta tarea. Revise primero los puntos $1$, $2$, $3$ y $4$ para evaluar esta celda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1FOd5wKszlX9"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.utils.validation import check_is_fitted\n","# 1. Cargar Wine en formato X, y\n","X6, y6 = load_X_y()\n","assert isinstance(X6, np.ndarray) and isinstance(y6, np.ndarray), \"Revise el ejercicio 1\"\n","\n","# 2. Problema de clasificación binaria\n","X6, y6 = bin_X_y(X6, y6)\n","assert isinstance(X6, np.ndarray) and isinstance(y6, np.ndarray), \"Revise el ejercicio 2\"\n","\n","# 3. Generar particiones de entrenamiento y prueba con estratificación\n","X6_train, X6_test, y6_train, y6_test = get_stratified_split(X6, y6)\n","assert np.all([isinstance(par, np.ndarray) \n","       for par in (X6_train, X6_test, y6_train, y6_test)]), \"Revise el ejercicio 3\"\n","\n","# 4. Entrenamiento de un clasificador de  k  vecinos más cercanos\n","clf6 = clasificador_knn(X6_train, y6_train, k = 1)\n","check_is_fitted(clf6)\n","assert isinstance(clf6, sklearn.neighbors._classification.KNeighborsClassifier), \"Revise el ejercicio 4\"\n","\n","prec, rec, f1 = métricas_binarias(clf6, X6_test, y6_test)\n","\n","if np.all([isinstance(x, Number) for x in [prec, rec, f1]]):  \n","  print(\"Precisión en prueba: \\t{:.4f}\".format(prec))\n","  print(\"Recall en prueba: \\t{:.4f}\".format(rec))\n","  print(\"F1 en prueba: \\t\\t{:.4f}\".format(f1))\n","else: print(\"Alguno de los valores retornados no es un número válido.\")"]},{"cell_type":"markdown","metadata":{"id":"uyr3AxArzlX-"},"source":["**Salida esperada:**\n","\n","```\n","Precisión en prueba:    0.8636\n","Recall en prueba:       0.9048\n","F1 en prueba:           0.8837\n","```"]},{"cell_type":"markdown","metadata":{"id":"9paK3pq1WItI"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Utilice los métodos **`precision_score`**, **`recall_score`** y **`f1_score`** del módulo **`sklearn.metrics`**.\n"]},{"cell_type":"markdown","metadata":{"id":"1ZOAT2bAYCwZ"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n","</summary>\n","\n","\n","* Para utilizar los métodos deberá realizar la predicción a partir del arreglo **`X`** y evaluar el desempeño con respecto al vector real de etiquetas **`y`**.\n"]},{"cell_type":"markdown","metadata":{"id":"ZmOu3KRC-G7J"},"source":["## **7. Métricas de desempeño multiclase**\n","----\n","Cuando se desarrolla un clasificador en el contexto de un problema multiclase, es importante considerar el desempeño general con formas de promediar la métrica obtenida por cada pareja de clases al considerarlas subproblemas de clasificación binaria.\n","\n","Desarrolle la función **`métrica_multiclase`** que calcule la métrica precisión, _recall_ o _F1_ según el tipo de métrica **`metric_type`**, y que realice la agregación de las submétricas por medio del tipo de operación de promedio **`avg_type`**. El resultado de esta métrica se debe obtener a partir de los vectores de etiquetas reales (**`y_real`**) y predichas por un modelo (**`y_pred`**).\n","\n","**Entrada**:\n","  * **`y_real`**: arreglo de *NumPy* de tamaño $(n, )$ con las etiquetas reales.\n","  * **`y_pred`**: arreglo de *NumPy* de tamaño $(n, )$ con las etiquetas predichas por un modelo de clasificación.\n","  * **`metric_type`**: cadena de texto con el tipo de métrica a calcular. Esta debe ser una de estas cadenas:\n","    ```python\n","    ['f1', 'recall', 'precision']\n","    ```\n","  * **`avg_type`**: cadena de texto con el tipo de operación usada para calcular el promedio de las métricas binarias individuales. Esta debe ser una de estas cadenas:\n","      ```python\n","    ['macro', 'micro', 'weighted']\n","    ```\n","\n","**Salida**:\n","\n","  * **`score`**: número real, métrica de tipo **`metric_type`** con promedio **`avg_type`** calculada sobre las etiquetas **`y_real`** y **`y_pred`**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WRnSL7Kz-Eh9"},"outputs":[],"source":["# FUNCIÓN CALIFICADA métrica_multiclase:\n","\n","# Módulo necesario para realizar el ejercicio.\n","from sklearn import metrics\n","\n","def métrica_multiclase(y_pred, y_real, metric_type, avg_type):\n","    \"\"\"\n","     y_real: arreglo de NumPy de shape (n,) con las etiquetas reales.\n","     y_pred: arreglo de NumPy de shape (n,) con las etiquetas predichas.\n","     metric_type: cadena de texto con el tipo de métrica. Uno de ['f1', 'recall', 'precision'].\n","     avg_type: cadena de texto con el tipo de promedio realizado. Uno de ['macro', 'micro', 'weighted'].\n","    Retorna:\n","     metric: métrica correspondiente al tipo 'metric_type' y criterio\n","             de promedio 'avg_type' evaluada entre 'y_pred' y 'y_real'.\n","    \n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 3-4 líneas de código)\n","  \n","    score = None\n","\n","    ### FIN DEL CÓDIGO ###\n","    return score"]},{"cell_type":"markdown","metadata":{"id":"RmaoFMwQ_773"},"source":["Use la siguiente celda para probar su función:"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ln16Ynm9sm_p"},"outputs":[],"source":["#TEST_CELL\n","X7, y7 = datasets.make_classification(n_features= 6, weights = (0.75, 0.25), random_state = 100)\n","\n","X7_train, y7_train = X7[:50], y7[:50]\n","X7_test, y7_test = X7[50:], y7[50:]\n","\n","clf7 = LogisticRegression().fit(X7_train, y7_train)\n","y7_pred = clf7.predict(X7_test)\n","\n","for metric_type in ['f1', 'recall', 'precision']:\n","  for avg_type in ['macro', 'micro', 'weighted']:\n","    score = métrica_multiclase(y7_test, y7_pred, metric_type, avg_type)\n","    if not isinstance(score, Number):\n","      print(f\"El score {metric_type} {avg_type} no es un número válido.\")\n","    else:\n","      print(\"Métrica {}, avg {}: {:.4f}\".format(metric_type, avg_type, score))"]},{"cell_type":"markdown","metadata":{"id":"05jXLFNcvT53"},"source":["**Salida esperada:**\n","\n","```\n","Métrica f1, avg macro: 0.8024\n","Métrica f1, avg micro: 0.8600\n","Métrica f1, avg weighted: 0.8579\n","Métrica recall, avg macro: 0.7939\n","Métrica recall, avg micro: 0.8600\n","Métrica recall, avg weighted: 0.8600\n","Métrica precision, avg macro: 0.8124\n","Métrica precision, avg micro: 0.8600\n","Métrica precision, avg weighted: 0.8566\n","```"]},{"cell_type":"markdown","metadata":{"id":"ua0zxdhk_PNL"},"source":["Para probar la función vamos a entrenar un clasificador para las $3$ clases originales del conjunto de datos *Wine*. \n","> **Nota**: El resultado de esta celda depende de la correctitud de los primeros puntos de esta tarea. Revise primero los puntos $1$, $3$ y $4$ antes de evaluar esta celda."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BIMBQFB6_hR2"},"outputs":[],"source":["#TEST_CELL\n","from sklearn.utils.validation import check_is_fitted\n","\n","# 1. Cargar Wine en formato X, y\n","X7, y7 = load_X_y()\n","assert isinstance(X7, np.ndarray) and isinstance(y7, np.ndarray), \"Revise el ejercicio 1\"\n","\n","# 3. Generar particiones de entrenamiento y prueba con estratificación\n","X7_train, X7_test, y7_train, y7_test = get_stratified_split (X7, y7)\n","assert np.all([isinstance(par, np.ndarray) \n","       for par in (X7_train, X7_test, y7_train, y7_test)]), \"Revise el ejercicio 3\"\n","\n","# 4. Entrenamiento de un clasificador de  k  vecinos más cercanos\n","clf7 = clasificador_knn(X7_train, y7_train, k = 1)\n","check_is_fitted(clf7)\n","assert isinstance(clf7, sklearn.neighbors._classification.KNeighborsClassifier), \"Revise el ejercicio 4\"\n","\n","y7_pred = clf7.predict(X7_test)\n","\n","for avg_type in ['macro', 'micro', 'weighted']:\n","  f1_train = métrica_multiclase(y7_train, clf7.predict(X7_train), 'f1', avg_type)\n","  if not isinstance(f1_train, Number): print(f\"El valor 'f1_train' ({avg_type}) no es un número válido.\")\n","  else: print(f\"F1 {avg_type} en entrenamiento: \\t{f1_train:.6f}\")\n","  \n","  f1_test = métrica_multiclase(y7_test, clf7.predict(X7_test), 'f1', avg_type)\n","  if not isinstance(f1_test, Number): print(f\"El valor 'f1_test' ({avg_type}) no es un número válido.\")\n","  else: print(f\"F1 {avg_type} en prueba: \\t\\t{f1_test:.6f}\")"]},{"cell_type":"markdown","metadata":{"id":"USJzn9FazTmm"},"source":["**Salida esperada:**\n","\n","```\n","F1 macro en entrenamiento:     1.000000\n","F1 macro en prueba:            0.701783\n","F1 micro en entrenamiento:     1.000000\n","F1 micro en prueba:            0.703704\n","F1 weighted en entrenamiento:  1.000000\n","F1 weighted en prueba:         0.701079\n","```"]},{"cell_type":"markdown","metadata":{"id":"x2PGHimbAqUC"},"source":["Como se puede ver el desempeño del modelo es muy bueno en el conjunto de entrenamiento, pero no es tan bueno en el conjunto de prueba. Esto sugiere que podemos tener ***sobreajuste***. En el siguiente ejercicio vamos a encontrar un mejor hiperparámetro $k$ para el algoritmo de entrenamiento."]},{"cell_type":"markdown","metadata":{"id":"FjRW0ujhaq31"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Según la entrada, deberá usar alguno de los métodos **`precision_score`**, **`recall_score`** y **`f1_score`** del módulo **`sklearn.metrics`**. Además, este método recibe el argumento **`average`** con el tipo de operación de promedio a calcular.\n"]},{"cell_type":"markdown","metadata":{"id":"lHgcjzq7BKa1"},"source":["## **8. Estimación de la complejidad**\n","---\n","Para prevenir problemas como el sobreajuste y subajuste de nuestro modelo vamos a realizar una exploración visual del desempeño de los modelos entrenados con distintos valores del hiperparámetro $k$. Para esto utilizaremos la métrica **$F_1$ macro** y realizaremos una gráfica para identificar un valor apropiado.\n","\n","Desarrolle la función **`curva_complejidad_F1_macro`** para que reciba datos de entrenamiento, datos de prueba y una lista de valores para el hiperparámetro **`k`** del algoritmo de clasificación de los $k$ vecinos más cercanos, y retorne una lista con las métricas $F_1$ **macro** de prueba para cada uno de los clasificadores con los diferentes valores de **`k`**.\n","\n","> **Nota**: Se recomienda utilizar los resultados de los ejercicios $4$ (para entrenar el modelo de cada iteración) y $7$ (para obtener la métrica correspondiente).\n","\n","**Entrada**:\n","\n","\n","* **`X_train`**: arreglo de *NumPy* con tamaño $(n, m)$ con la partición de entrenamiento de **`X`**.\n","* **`X_test`**:  arreglo de *NumPy* con tamaño $(t, m)$ con la partición de prueba de **`X`**.\n","* **`y_train`**: arreglo de *NumPy* con tamaño $(n,)$ con la partición de entrenamiento de **`y`**.\n","* **`y_test`**:  arreglo de *NumPy* con tamaño $(t,)$ con la partición de prueba de **`y`**.\n","* **`k_vals`**: lista de números enteros de tamaño $K$ con los hiperparámetros $k$ del clasificador *KNN*.\n","\n","\n","**Salida**:\n","* **`f1_scores`**: lista o arreglo de *NumPy* de tamaño $K$ con el resultado de la métrica $F_1$ **macro** obtenida de la evaluación del desempeño del modelo de cada iteración. El orden debe corresponder al orden de los hiperparámetros **`k_vals`**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lNFguzr6Cdpr"},"outputs":[],"source":["# FUNCIÓN CALIFICADA curva_complejidad_F1_macro:\n","\n","def curva_complejidad_F1_macro(X_train, y_train, X_test, y_test, k_vals):\n","    \"\"\"\n","     X_train: arreglo de numpy de shape (n, m) con las características de entrenamiento.\n","     y_train: arreglo de numpy de shape (n,) con las etiquetas de clase de entrenamiento.\n","     X_test: arreglo de numpy de shape (n, m) con las características de prueba.\n","     y_test: arreglo de numpy de shape (n,) con las etiquetas de prueba.\n","     k_vals: lista de valores del hiperparámetro k del clasificador knn.\n","    Retorna:\n","     f1_scores: lista con el F1 macro para cada clasificador entrenado con los valores de k_vals.\n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 5-6 líneas de código)\n","  \n","    f1_scores = None\n","\n","    ### FIN DEL CÓDIGO ###\n","\n","    return f1_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"aJK1YKrTDxKw"},"outputs":[],"source":["#TEST_CELL\n","#@title { run: \"auto\" }\n","#@markdown **Celda de pruebas:** Ejecute esta celda para generar una visualización de la curva de complejidad obtenida a partir del conjunto de datos *Wine*. Esta función utiliza el resultado de las funciones anteriores para el entrenamiento del modelo.\n","\n","#@markdown A continuación graficamos los valores del **_F1 macro_** para los diferentes valores del hiperparámetro **`k`**:\n","\n","max_k = 15 \n","\n","# 1. Cargar Wine en formato X, y\n","X8, y8 = load_X_y()\n","assert isinstance(X8, np.ndarray) and isinstance(y8, np.ndarray), \"Ej 1. Revise el ejercicio 1.\"\n","\n","# 3. Generar particiones de entrenamiento y prueba con estratificación\n","X8_train, X8_test, y8_train, y8_test = get_stratified_split (X8, y8)\n","assert np.all([isinstance(par, np.ndarray) \n","       for par in (X8_train, X8_test, y8_train, y8_test)]), \"Ej 3. Revise el ejercicio 3.\"\n","\n","k_vals = np.arange(1, max_k + 1)\n","f1_scores = curva_complejidad_F1_macro(X8_train, y8_train, X8_test, y8_test, k_vals)\n","assert (f1_scores is not None and len(f1_scores) == len(k_vals)\n","        ), \"Ej 8. El arreglo retornado no es válido.\"\n","plt.plot(k_vals, f1_scores);\n","plt.xlabel(\"$k$\")\n","plt.ylabel(\"$F_1$ score macro\")\n","plt.xlim([0, max_k + 1])\n","plt.title(\"Curva de complejidad $F_1$\", fontdict=dict(family = 'serif', size = 20));"]},{"cell_type":"markdown","metadata":{"id":"G3qsOLNjFlVh"},"source":["¿Qué valor de **`k`** escogería? Recuerde que el $F_1$ _score_ es una métrica que queremos **maximizar**."]},{"cell_type":"markdown","metadata":{"id":"L5pQE4RybAi0"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Para cada valor de **`k_vals`** deberá generar un clasificador nuevo y realizar una predicción a partir de la partición de prueba de la matriz de datos de entrada para calcular la métrica respectiva. Se le recomienda usar la función del ejercicio $4$ para entrenar el modelo y la función del ejercicio $7$ para obtener el valor de la métrica y almacenarlo tras cada iteración.\n"]},{"cell_type":"markdown","metadata":{"id":"xpEWAW102m23"},"source":["## **9. Estimación de la complejidad en regresión**\n","---\n","Elegir un hiperparámetro adecuado también depende de la elección adecuada de la métrica de desempeño usada como valor de referencia. Para elegir la métrica adecuada es importante entender la naturaleza del problema y distinguir si es un problema de clasificación o de regresión. \n","\n","En este último ejercicio deberá desarrollar la función **`curva_complejidad_regresion`**, que reciba datos de entrenamiento, datos de prueba y una lista de valores para el hiperparámetro **`k`** del algoritmo de regresión de los $k$ vecinos más cercanos, y retorne una lista con los valores el **RMSE** de prueba para cada uno de los regresores con los diferentes valores de **`k`**.\n","\n","**Entrada**:\n","\n","\n","* **`X_train`**: arreglo de *NumPy* con tamaño $(n, m)$ con la partición de entrenamiento de **`X`**.\n","* **`X_test`**:  arreglo de *NumPy* con tamaño $(t, m)$ con la partición de prueba de **`X`**.\n","* **`y_train`**: arreglo de *NumPy* con tamaño $(n,)$ con la partición de entrenamiento de **`y`**.\n","* **`y_test`**:  arreglo de *NumPy* con tamaño $(t,)$ con la partición de prueba de **`y`**.\n","* **`k_vals`**: lista de números enteros de tamaño $K$ con los hiperparámetros $k$ del regresor *KNN*.\n","\n","\n","**Salida**:\n","* **`rmse_scores`**: lista o arreglo de *NumPy* de tamaño $K$ con el resultado de la métrica **RMSE** obtenida de la evaluación del desempeño del modelo de cada iteración. El orden debe corresponder al orden de los hiperparámetros **`k_vals`**.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BYr-N1fgvZQR"},"outputs":[],"source":["# FUNCIÓN CALIFICADA curva_complejidad_regresion:\n","\n","# Módulo necesario para calcular la métrica RSME.\n","from sklearn import metrics\n","\n","# Módulo necesario para declarar el modelo de regresión KNN.\n","from sklearn import neighbors\n","\n","def curva_complejidad_regresion(X_train, y_train, X_test, y_test, k_vals):\n","    \"\"\"\n","     X_train: arreglo de NumPy de tamaño (n, m) con las características de entrenamiento.\n","     y_train: arreglo de NumPy de tamaño (n,) con las etiquetas de clase de entrenamiento.\n","     X_test: arreglo de NumPy de tamaño (n, m) con las características de prueba.\n","     y_test: arreglo de NumPy de tamaño (n,) con las etiquetas de prueba.\n","     k_vals: lista de valores del hiperparámetro k del regresor KNN.\n","    Retorna:\n","     rmse_scores: lista con el RMSE para cada regresor entrenado con los valores de k_vals.    \n","    \"\"\"\n","    ### ESCRIBA SU CÓDIGO AQUÍ ### (~ 5-6 líneas de código)\n","  \n","    rmse_scores = None\n","\n","    ### FIN DEL CÓDIGO ###\n","    return rmse_scores"]},{"cell_type":"code","execution_count":null,"metadata":{"cellView":"form","id":"V1QHOxnKAxm_"},"outputs":[],"source":["max_k = 15 \n","\n","X9, y9 = datasets.load_boston(return_X_y=True)\n","X9_train, X9_test, y9_train, y9_test = model_selection.train_test_split(X9, y9, test_size=0.3, random_state=23)\n","k_vals = np.arange(1, max_k + 1)\n","rsme_scores = curva_complejidad_regresion(X9_train, y9_train, X9_test, y9_test, k_vals)\n","\n","assert (rsme_scores is not None and len(rsme_scores) == len(k_vals)\n","        ), \"Ej 9. El arreglo 'scores' retornado no es válido.\"\n","\n","plt.plot(k_vals, rsme_scores);\n","plt.xlabel(\"$k$\")\n","plt.ylabel(\"RSME\")\n","plt.xlim([0, max_k + 1])\n","plt.title(\"Curva de complejidad RSME\", fontdict=dict(family = 'serif', size = 20));\n"]},{"cell_type":"markdown","metadata":{"id":"szFfGlZt2ZyW"},"source":["¿Qué valor de $k$ escogería? Recuerde que el **RMSE** es una métrica que queremos **minimizar**."]},{"cell_type":"markdown","metadata":{"id":"FBS3gfzOc-dz"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 1</b></font>\n","</summary>\n","\n","\n","* Para cada valor de **`k_vals`** deberá generar un **regresor** nuevo y realizar una predicción a partir de la partición de prueba de la matriz de datos de entrada para calcular la métrica respectiva."]},{"cell_type":"markdown","metadata":{"id":"8koZ4mFldNs5"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 2</b></font>\n","</summary>\n","\n","\n","* Deberá declarar el modelo de regresión con el constructor **`KNeighborsRegressor`** del módulo **`sklearn.neighbors`**."]},{"cell_type":"markdown","metadata":{"id":"cgC3s26Cd7pU"},"source":["<details>    \n","<summary>\n","    <font size=\"3\" color=\"darkgreen\"><b>Pista 3</b></font>\n","</summary>\n","\n","\n","* La métrica corresponde a la raíz cuadrada del valor obtenido con el método **`mean_squared_error`** del módulo **`sklearn.metrics`**, a partir de la etiqueta de valores reales **`y_test`** y el vector de valores predichos a partir del arreglo **`X_test`**."]}],"metadata":{"colab":{"name":"Copia de M2U2 - Tarea 2 - Desarrollo de modelos de aprendizaje computacional.ipynb","provenance":[{"file_id":"1xAl6cju_7fer06aCqPvf7n8XT3v-8EL5","timestamp":1618957193073}]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}
